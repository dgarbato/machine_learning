{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67875a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5788a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aa94e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613f256a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from regression_function import regx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f7569dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vars_data = pd.read_csv(r'C:\\Users\\dgarb\\OneDrive\\Documents\\Data Science Bootcamp August\\Machine Learning Project\\data\\model_vars_data.csv',index_col=0)\n",
    "\n",
    "test_vars_data = pd.read_csv(r'C:\\Users\\dgarb\\OneDrive\\Documents\\Data Science Bootcamp August\\Machine Learning Project\\data\\test_vars_data.csv',index_col=0)\n",
    "\n",
    "price_train = pd.read_csv(r'C:\\Users\\dgarb\\OneDrive\\Documents\\Data Science Bootcamp August\\Machine Learning Project\\data\\y_train.csv',index_col=0)\n",
    "\n",
    "price_test = pd.read_csv(r'C:\\Users\\dgarb\\OneDrive\\Documents\\Data Science Bootcamp August\\Machine Learning Project\\data\\y_test.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f67c1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def miss_cols(df):\n",
    "    missing = np.sum(df.isnull(),axis=0)\n",
    "    \n",
    "    miss_ind = np.sum(df.isnull(),axis=0) > 0\n",
    "    \n",
    "    vals = pd.Series(filter(lambda x: x != 0,missing))\n",
    "     \n",
    "    cols_miss = df.columns[miss_ind]\n",
    "\n",
    "    L=list(zip(cols_miss,vals, round(vals/df.shape[0],4)))\n",
    "    \n",
    "    return sorted(L,reverse=True,key=lambda x: x[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad5ff3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_vars_data.drop(['GarageYrBlt'],axis=1, inplace = True)\n",
    "miss_cols(model_vars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbc5fd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vars_data.drop(['GarageYrBlt'],axis=1, inplace = True)\n",
    "miss_cols(test_vars_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15309ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_keep(it_lasso, amt):\n",
    "    keeps1 = it_lasso.loc[it_lasso['abs_val'] > amt,['features']]\n",
    "    list_keeps1 = list(keeps1.features)\n",
    "    return list_keeps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d25403a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regx2(model= None,\n",
    "x_train = None,\n",
    "x_test = None,\n",
    "y_train = None,\n",
    "y_test = None,\n",
    "params = None, #put dictionary of params\n",
    "cv_ = 5,\n",
    "linear_reg = True,\n",
    "tree_based = False) :\n",
    "######################################\n",
    "#########################################\n",
    "\n",
    "    features = list(x_train.columns)\n",
    "\n",
    "    ss = StandardScaler()\n",
    "    x_train = ss.fit_transform(x_train)\n",
    "    x_test = ss.transform(x_test)\n",
    "\n",
    "    gs = GridSearchCV(model, params, cv=cv_, return_train_score=True, refit=True)\n",
    "    gs.fit(x_train,y_train)\n",
    "    gs.best_params_\n",
    "\n",
    "    model= gs.best_estimator_\n",
    "    ###################################    \n",
    "\n",
    "    print('best params: ',gs.best_params_)\n",
    "    print('score: ',gs.score(x_train,y_train))\n",
    "    print('  ')\n",
    "    print('test score: ',gs.score(x_test,y_test))\n",
    "\n",
    "\n",
    "    if linear_reg:\n",
    "        adj_r2 = 1-(1-gs.score(x_train,y_train))*(x_train.shape[0] - 1) / (x_train.shape[0] - x_train.shape[1] - 1)\n",
    "        print('adj_r2: ', adj_r2)\n",
    "        adj_r2_test = 1-(1-gs.score(x_test,y_test))*(x_test.shape[0] - 1) / (x_test.shape[0] - x_test.shape[1] - 1)\n",
    "        print('  ')\n",
    "        print('adj_r2_test: ',adj_r2_test)\n",
    "        print(' ')\n",
    "\n",
    "\n",
    "    train_pred = gs.best_estimator_.predict(x_train)\n",
    "    print('train RMSE: ' + str(mean_squared_error(train_pred,y_train)**0.5))\n",
    "    print('  ')\n",
    "\n",
    "    test_pred = gs.best_estimator_.predict(x_test)\n",
    "    print('test RMSE: ' + str(mean_squared_error(test_pred,y_test)**0.5))\n",
    "\n",
    "    if linear_reg:\n",
    "\n",
    "        coefs = pd.Series(gs.best_estimator_.coef_, name = 'coef' )\n",
    "\n",
    "        varnames = pd.Series(features, name = 'features')\n",
    "\n",
    "        pd.set_option('display.max_rows', None) # or 1000.\n",
    "\n",
    "        abs_coefs = pd.Series(np.abs(coefs),name = 'abs_val')\n",
    "\n",
    "        coefs_ = pd.concat([varnames,coefs, abs_coefs], axis=1)\n",
    "\n",
    "        #return:\n",
    "        model_importances = coefs_.sort_values(by=['abs_val'], ascending=False)\n",
    "\n",
    "        print(model_importances)\n",
    "        print(' ')\n",
    "\n",
    "    elif tree_based:\n",
    "        pd.set_option('display.max_rows', None) # or 1000.\n",
    "\n",
    "        #return\n",
    "        varnames = pd.Series(features, name = 'features')\n",
    "\n",
    "        importances_ = pd.Series(model.feature_importances_, name = 'importances')\n",
    "\n",
    "        df = pd.concat([varnames,importances_], axis=1)\n",
    "\n",
    "        model_importances = df.sort_values(by=['importances'], ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "    #         model_importances = pd.Series(model.feature_importances_, index = features).sort_values(ascending=False)\n",
    "\n",
    "        print(model_importances)\n",
    "\n",
    "\n",
    "    if linear_reg:\n",
    "        residuals = y_train - train_pred\n",
    "        print('skewness: ',stats.skew(residuals))\n",
    "        print(' ')\n",
    "        sns.set_theme(style='darkgrid')\n",
    "        sns.histplot(residuals, bins=20);\n",
    "    \n",
    "    print('model_importances.shape: ',model_importances.shape)\n",
    "    return model_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88ff7a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StandardScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17788/4054111979.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m ridge1 = regx2(model= Ridge(max_iter=3000),\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_vars_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_vars_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSalePrice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprice_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSalePrice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documents\\Data Science Bootcamp August\\Machine Learning Project\\regression_function.py\u001b[0m in \u001b[0;36mregx2\u001b[1;34m(model, x_train, x_test, y_train, y_test, params, cv_, linear_reg, tree_based)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
     ]
    }
   ],
   "source": [
    "ridge1 = regx2(model= Ridge(max_iter=3000),\n",
    "x_train = model_vars_data,\n",
    "x_test = test_vars_data,\n",
    "y_train = np.log(price_train.SalePrice),\n",
    "y_test = np.log(price_test.SalePrice),\n",
    "params = {\"alpha\": [0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000]},\n",
    "cv_ = 5,\n",
    "linear_reg = True,\n",
    "tree_based = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
